# PySpark-Learning

---

**PySpark** is used in Data Science to handle big data efficiently.

It lets you process and analyze large datasets in parallel across multiple machines, using Python with the power of Apache Spark.

ðŸ‘‰ **In short:** PySpark = Python + Spark = Fast, scalable big data analysis.

#### ðŸš€ 30-Day PySpark Personal Learning Plan
---
**Week-1:** Foundations

**Goal:** Build Python & SQL skills, get PySpark running locally.
<details>
  <summary>Week-1: Foundations </summary>

  **Goal:** Build Python & SQL skills, get PySpark running locally.
  - **[ðŸ“˜ Day 00:](Day00.md)** Generic 
  - **[ðŸ“˜ Day 01:](Day01.md)** Python Basics
  - **[ðŸ“˜ Day 02:](Day02.md)** Python Basics (Functions, File handling)
  - **[ðŸ“˜ Day 03:](Day03.md)** Learn Pandas (DataFrames, Filtering)
  - **[ðŸ“˜ Day 04:](Day04.md)** Learn Pandas (Grouping, Joins/Merge)
  - **[ðŸ“˜ Day 05:](Day05.md)** Brush up SQL (SELECT, WHERE, GROUP BY, JOIN)
  - **[ðŸ“˜ Day 06:](Day06.md)** Introduction to PySpark
  - **[ðŸ“˜ Day 07:](Day07.md)**Installing PySpark & Run Script

</details>

**Week-2:** PySpark Core APIs

**Goal:** Master DataFrames & Spark SQL.

**Week-3:**  Infra + Spark Cluster Skills

**Goal:** Go beyond single-node, use infra knowledge.

**Week-4:**  Advanced + Real Projects

**Goal:** Solve real-world problems.